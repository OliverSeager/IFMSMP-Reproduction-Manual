{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 - Purging the Series of the Fed Information Effect\n",
    "\n",
    "This script purges the series created in 1.2 of the Fed Information Effect using the Greenbook forecast data gathered in 1.3. Following Mirranda-Aggripino (2016), taking $s_t$ to be the raw shock for meeting $t$ calculated in 1.2 and $\\Gamma_t$ to be a vector of Greenbook forecast data corresponding to meeting $t$, I take $u_t$ to be the *true* shock - that which cannot be explained by the beliefs the Fed currently has about real GDP growth, inflation and unemployment for the current and next 4 quarters, conducting OLS regression as follows...\n",
    "\n",
    "$$s_t = \\alpha + \\mathbf{\\beta}\\cdot\\mathbf{\\Gamma}_t + u_t$$\n",
    "\n",
    "Potential specifications for $\\Gamma$ are constructed from forecast revisions for...\n",
    "- all non-empty combinations of real GDP growth, inflation and unemployment.\n",
    "- Only the current quarter $q_0$, or all data through to $q_1$, $q_2$, $q_3$ or $q_4$, or only data for $q_0$ and $q_4$, or only data for $q_0$,$q_1$ and $q_4$\n",
    "\n",
    "...providing $7\\cdot7=49$ possible specifications.\n",
    "\n",
    "Specifcations taken forth are...\n",
    "##### Rewrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preamble\n",
    "\n",
    "This script makes use of...\n",
    "\n",
    "- Pandas\n",
    "- StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Raw Shock Dataframe\n",
    "\n",
    "This block imports the raw shock dataframe created in 1.2, and fixes the date indices such that it is commensurable with the Greenbook forecast dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "shock_df = pd.read_csv('shock.csv')\n",
    "\n",
    "shock_df = shock_df.rename(columns = {'Unnamed: 0':'Date'})\n",
    "\n",
    "shock_df['Date'] = [pd.Timestamp(date) for date in shock_df['Date']] # .csv format saves dates as strings; this gets them back into Pandas timestamp format\n",
    "                                                                     \n",
    "shock_df = shock_df.set_index('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Greenbook Dataframe\n",
    "\n",
    "This block imports the greenbook forecast revisions dataframe created in 1.3, fixes the date indices, and corrects for rounding errors from storage in Unix timestamp format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "greenbook_df = pd.read_csv('greenbook.csv')\n",
    "\n",
    "greenbook_df = greenbook_df.rename(columns = {'Unnamed: 0': ''})\n",
    "\n",
    "greenbook_df = greenbook_df.set_index('')\n",
    "\n",
    "greenbook_df = greenbook_df.T\n",
    "\n",
    "greenbook_df.index = [pd.Timestamp(int(ts) + 21600 - ((int(ts) + 21600) % 86400), unit = 's') for ts in greenbook_df.index]\n",
    "\n",
    "greenbook_df.index.name = 'Date'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Matching Dataframe Indices\n",
    "\n",
    "This block drops Greenbook forecast revision data for meeting dates for which I have no shock (currently just 12th November, 1997) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices align.\n"
     ]
    }
   ],
   "source": [
    "## Drop dates for which no shocks\n",
    "\n",
    "greenbook_df = greenbook_df.drop(index = greenbook_df.index[[date not in shock_df.index for date in greenbook_df.index]])\n",
    "\n",
    "## Check for any dates in the shock index that are not in the Greenbook index (misalignment likely reflects an error in 1.1).\n",
    "\n",
    "if list(greenbook_df.index) == list(shock_df.index):\n",
    "    \n",
    "    print('Indices align.')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('Indices do not align.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising the Regressor and Regressand Dataframes\n",
    "\n",
    "This block gets the raw shock into a single-column regressand dataframe, and adds a constant (i.e. a column of only 1s) to the Greenbook forecast dataframe. The OLS regression method in the StatsModels package is compatible with pandas dataframes, so the data are stored this way as an expedient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressand_df = shock_df.drop(columns = shock_df.columns[:-1])\n",
    "\n",
    "regressors_df = sm.add_constant(greenbook_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting String Lists for Each Potential Specification\n",
    "\n",
    "This block uses some mathematical chicanery to get each of the 49 specifications mentioned above from `spec_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "spec_list = [['rgdp_q0','rgdp_q1','rgdp_q2','rgdp_q3','rgdp_q4'],\n",
    "            ['infl_q0', 'infl_q1', 'infl_q2', 'infl_q3', 'infl_q4'],\n",
    "            ['unmp_q0', 'unmp_q1', 'unmp_q2', 'unmp_q3', 'unmp_q4']]\n",
    "\n",
    "def select(List, indices): # This function allows for getting non-consecutive elements from a list.\n",
    "    return [List[i] for i in indices]\n",
    "\n",
    "## Get a set of indices for combinations of real GDP growth, inflation and unemployment.\n",
    "\n",
    "index_list_variables = [select(range(0,15,5),I) for I in [[0],[1],[2],[0,1],[0,2],[1,2],[0,1,2]]]\n",
    "\n",
    "index_list_full = []\n",
    "\n",
    "for item in index_list_variables: # This loop gets a set of indices for each of 0, 1, 2, 3 and 4 quarters out.\n",
    "    \n",
    "    for i in range(0,5):\n",
    "        \n",
    "        periods = []\n",
    "        \n",
    "        for j in item:\n",
    "            \n",
    "            periods = periods + [j + k for k in range(0,i+1)]\n",
    "            \n",
    "        index_list_full.append(periods)\n",
    "    \n",
    "for item in index_list_variables:\n",
    "    \n",
    "    add04 = []\n",
    "    \n",
    "    add014 = []\n",
    "    \n",
    "    for x in [[j,j+1,j+4] for j in item]:\n",
    "        \n",
    "        add04 = add04 + [x[0]] + [x[2]]\n",
    "        \n",
    "        add014 = add014 + x\n",
    "    \n",
    "    index_list_full.append(add04)\n",
    "    \n",
    "    index_list_full.append(add014)\n",
    "\n",
    "spec_list_full = [select(list(regressors_df.columns[1:]),subset) for subset in index_list_full] # Gets each specification in terms of strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Dataframe for Specification Analysis\n",
    "\n",
    "This block gets the Akaike Information Criterion, Adjusted $R^2$, $R^2$ and number of regressors (`n`) for each specification into a single dataframe, allowing for analysis of each using Pandas' `.sort_values()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialise (rather ugly) dataframe - specifications as index and information for analysis as columns\n",
    "\n",
    "spec_df = pd.DataFrame(index = [','.join(s) for s in spec_list_full], columns = ['aic','adj_R^2','R^2','n'])\n",
    "\n",
    "for spec in spec_list_full: # Loops through each specification\n",
    "    \n",
    "    columns = ['const'] + spec\n",
    "    \n",
    "    model = sm.OLS(regressand_df, regressors_df[columns]).fit() # This is the fitting of the model\n",
    "    \n",
    "    spec_df.loc[','.join(spec),'aic'] = model.aic\n",
    "    \n",
    "    spec_df.loc[','.join(spec),'adj_R^2'] = model.rsquared_adj\n",
    "    \n",
    "    spec_df.loc[','.join(spec),'R^2'] = model.rsquared\n",
    "    \n",
    "    spec_df.loc[','.join(spec),'n'] = len(spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Purged Shock Series Dataframe\n",
    "\n",
    "This block produces the OLS model for each series carried forth (justifications given above) and gets the residuals into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_subset = 'rgdp_q0,rgdp_q1,rgdp_q4,infl_q0,infl_q1,infl_q4'.split(',')\n",
    "\n",
    "S_model = sm.OLS(regressand_df, regressors_df[S_subset]).fit()\n",
    "\n",
    "full_model = sm.OLS(regressand_df, regressors_df).fit() # The full model\n",
    "\n",
    "purged_shocks_df = pd.DataFrame(index = greenbook_df.index)\n",
    "\n",
    "purged_shocks_df['S_shocks'] = S_model.resid # This gets the residuals for each value\n",
    "\n",
    "purged_shocks_df['full_shocks'] = full_model.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to *.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "purged_shocks_df.to_csv('purged_shocks.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
