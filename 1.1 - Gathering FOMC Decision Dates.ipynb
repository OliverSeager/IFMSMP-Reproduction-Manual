{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 - Gathering FOMC Decision Dates\n",
    "\n",
    "This script obtains all scheduled FOMC decision dates from February 1994, when The Fed started releasing a statement after every meeting (Gurkaynak, Sack and Swanson, 1994) through to the last date for which Greenbook forecasts are available (accomodating the Mirranda-Aggripino (2016) method of purging shock series of the Fed Information effect).\n",
    "\n",
    "The script pulls dates from each **federalreserve.gov/monetarypolicy/fomchistorical*yyyy*.htm** page with *yyyy* denoting the year of interest. \"Historical\" meetings on the Fed website are those for which Greenbook forecasts have been released, so this method attains only those by default. \n",
    "\n",
    "Dates are exported to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals = [\"cat\", \"mouse\", \"horse\"]\n",
    "animals[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'mouse']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preamble\n",
    "\n",
    "This script makes use of...\n",
    "\n",
    "- `urrlib`\n",
    "- Regular Expressions (`re`)\n",
    "- `datetime`\n",
    "- `time`\n",
    "- `csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables for Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current year\n",
    "\n",
    "current_year = datetime.now().year\n",
    "\n",
    "# Get list of years\n",
    "\n",
    "data_years = range(1994, current_year + 1)\n",
    "\n",
    "# List to which dates appended\n",
    "\n",
    "dates = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 15 September 2003, which is erroneously listed as separate from the \n",
      "                                                  Sep 16, 2003 meeting on the Fed website\n"
     ]
    }
   ],
   "source": [
    "# Loop\n",
    "\n",
    "for year in data_years:\n",
    "    \n",
    "    year_string = str(year)\n",
    "    \n",
    "    url = \"http://www.federalreserve.gov/monetarypolicy/fomchistorical\" + year_string + \".htm\"\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        xmlstring = str(urllib.request.urlopen(url).read())\n",
    "\n",
    "    except:\n",
    "        \n",
    "        continue\n",
    "        \n",
    "         # will fail if no FOMC meetings for which Greenbook released in this year (i.e. the past 5 years or so)\n",
    "        \n",
    "    preliminary_matches = re.findall(\"<h5(.*?)h5>\",xmlstring) # Fed website wasn't allowing for standard xml tree parsing\n",
    "                                                              # so RegEx string parsing used\n",
    "    \n",
    "    for match in preliminary_matches:\n",
    "        \n",
    "        # Each 'match' is a date\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            date = re.findall(\">(.*?) Meeting\", match)[0] # Isolates date component of string\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            continue\n",
    "        # Unscheduled meetings contain \"(unscheduled)\" in string instead of \"Meeting\", so are avoided by default\n",
    "        \n",
    "        if len(date.split()) == 2: # Handles \"Month/Month Date-Date\" format for overlaps (i.e. May/June 30-1)\n",
    "        \n",
    "            months = date.split()[0]\n",
    "        \n",
    "            month = months.split('/')[-1] # Takes second month if two\n",
    "    \n",
    "            days = date.split()[1]\n",
    "    \n",
    "            day = days.split('-')[-1] # Takes last date if multiple\n",
    "            \n",
    "            full_date = \" \".join([day, month, year_string]) # Concatenates into \"1 January 1994\" format\n",
    "            \n",
    "            ##### BUG FIX #####\n",
    "            if full_date == \"15 September 2003\":\n",
    "                \n",
    "                print(\"Skipped \" + full_date + \"\"\", which is erroneously listed as separate from the \n",
    "                                                  Sep 16, 2003 meeting on the Fed website\"\"\")\n",
    "                continue\n",
    "        \n",
    "        else:\n",
    "            # Handles \"Month Date-Month Date\" format for overlaps (i.e. May 30-June 1)\n",
    "            \n",
    "            month_day = date.split(\"-\")[1] # Removes first month & date\n",
    "            \n",
    "            month = month_day.split()[0]\n",
    "            \n",
    "            day = month_day.split()[1]\n",
    "            \n",
    "            full_date = \" \".join([day, month, year_string]) # Concatenates into \"1 January 1994\" format\n",
    "        \n",
    "        datetime_date = datetime.strptime(full_date, '%d %B %Y') # Converts String into datetime format\n",
    "        \n",
    "        unix_time = time.mktime(datetime_date.timetuple()) # Converts datetime format into Unix time\n",
    "        \n",
    "        #unix_time = unix_time + 43200 # Changes Unix time from midnight at start of date to midday of date, to avoid later   \n",
    "                                      # rounding errors (Times are in UTC).\n",
    "        \n",
    "        dates.append(unix_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to *.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dates.csv\", \"w\", newline='') as dates_file:\n",
    "    \n",
    "    wr = csv.writer(dates_file, quoting=csv.QUOTE_ALL)\n",
    "    \n",
    "    wr.writerow(dates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
